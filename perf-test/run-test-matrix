#!/usr/bin/env bash
#
# Run the full PicoShare performance test matrix with Firecracker
#
set -uo pipefail

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"

# Test matrix configuration
FILE_SIZES=("100M" "500M" "1G" "2G" "5G")
MEMORY_LIMITS=("2048" "1024" "512" "256")

RESULTS_BASE_DIR="$SCRIPT_DIR/results"

log() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $*"
}

# Create results directory
TIMESTAMP=$(date +%Y%m%d-%H%M%S)
RUN_DIR="$RESULTS_BASE_DIR/matrix-fc-$TIMESTAMP"
mkdir -p "$RUN_DIR"

SUMMARY_FILE="$RUN_DIR/summary.txt"
CSV_FILE="$RUN_DIR/matrix-results.csv"

# Initialize CSV
echo "ram_mb,file_size,boot_time_seconds,duration_seconds,throughput_mbps,http_status,exit_reason,success" > "$CSV_FILE"

log "==================================================="
log "PicoShare Firecracker Performance Test Matrix"
log "==================================================="
log "Memory configs: ${MEMORY_LIMITS[*]}"
log "File sizes: ${FILE_SIZES[*]}"
log "Total tests: $((${#MEMORY_LIMITS[@]} * ${#FILE_SIZES[@]}))"
log "Results directory: $RUN_DIR"
log ""

# Statistics
total_tests=$((${#MEMORY_LIMITS[@]} * ${#FILE_SIZES[@]}))
current_test=0
passed_tests=0
failed_tests=0
start_time=$(date +%s)

# Clean up any stale routes before starting
log "Cleaning up stale network routes..."
sudo ip route del 172.16.0.0/24 2>/dev/null || true

# Run tests
for memory in "${MEMORY_LIMITS[@]}"; do
    log "=========================================="
    log "Testing with ${memory}MB RAM"
    log "=========================================="
    log ""

    for size in "${FILE_SIZES[@]}"; do
        ((current_test++))
        log "[$current_test/$total_tests] Running: ${memory}MB RAM, ${size} file"

        # Clean up route before each test
        sudo ip route del 172.16.0.0/24 2>/dev/null || true

        # Run single test
        test_start=$(date +%s)

        # Run test and capture output
        if sudo "$SCRIPT_DIR/run-test" "$memory" "$size" 2>&1 | tee "$RUN_DIR/test-${memory}MB-${size}.log"; then
            result_file=$(grep '^/.*\.json$' "$RUN_DIR/test-${memory}MB-${size}.log" | tail -1)
            ((passed_tests++))
            test_status="PASS"
        else
            result_file=$(grep '^/.*\.json$' "$RUN_DIR/test-${memory}MB-${size}.log" | tail -1)
            ((failed_tests++))
            test_status="FAIL"
        fi

        test_end=$(date +%s)
        test_duration=$((test_end - test_start))

        # Extract result data and append to CSV
        if [[ -f "$result_file" ]] && command -v jq >/dev/null 2>&1; then
            jq -r '[.ram_mb, .file_size, .boot_time_seconds, .duration_seconds, .throughput_mbps, .http_status, .exit_reason, .success] | @csv' "$result_file" >> "$CSV_FILE"
        fi

        log "[$current_test/$total_tests] $test_status (took ${test_duration}s)"
        log ""

        # Brief pause between tests
        sleep 2
    done
done

end_time=$(date +%s)
total_duration=$((end_time - start_time))

# Generate summary
{
    echo "==================================================="
    echo "PicoShare Firecracker Performance Test Matrix Summary"
    echo "==================================================="
    echo ""
    echo "Timestamp: $(date -Iseconds)"
    echo "Total Duration: ${total_duration}s ($((total_duration / 60))m)"
    echo ""
    echo "Tests Run: $current_test / $total_tests"
    echo "Passed: $passed_tests"
    echo "Failed: $failed_tests"
    echo ""

    if [[ -f "$CSV_FILE" ]] && command -v column >/dev/null 2>&1; then
        echo "Results:"
        echo ""
        column -t -s',' "$CSV_FILE"
    fi
} | tee "$SUMMARY_FILE"

log ""
log "==================================================="
log "Test matrix complete!"
log "  Passed: $passed_tests"
log "  Failed: $failed_tests"
log "  Total:  $current_test"
log ""
log "Results saved to: $RUN_DIR"
log "==================================================="

exit $( [[ $failed_tests -eq 0 ]] && echo 0 || echo 1 )
