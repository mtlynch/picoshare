#!/usr/bin/env bash
#
# Run the full PicoShare performance test matrix with Firecracker
#
set -euo pipefail

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_ROOT="$(cd "$SCRIPT_DIR/.." && pwd)"

# Test matrix configuration
FILE_SIZES=("100M" "500M" "1G" "2G" "5G")
MEMORY_LIMITS=("2048" "1024" "512" "256")

RESULTS_BASE_DIR="$SCRIPT_DIR/results"

log() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $*"
}

# Build PicoShare binary
build_binary() {
    log "==================================================="
    log "Building PicoShare binary..."
    log "==================================================="

    cd "$PROJECT_ROOT"

    # Check if we're using ncruces2 driver (pure Go, no CGO)
    if grep -q 'github.com/ncruces/go-sqlite3' go.mod 2>/dev/null; then
        log "Detected ncruces2 driver - building with CGO_ENABLED=0"
        CGO_ENABLED=0 /usr/local/go/bin/go build -o "$PROJECT_ROOT/picoshare" ./cmd/picoshare
    else
        log "Building with standard Go (CGO enabled for mattn driver)"
        /usr/local/go/bin/go build -o "$PROJECT_ROOT/picoshare" ./cmd/picoshare
    fi

    if [[ ! -f "$PROJECT_ROOT/picoshare" ]]; then
        log "ERROR: Build failed - picoshare binary not found"
        exit 1
    fi

    log "✓ Build complete: $(ls -lh "$PROJECT_ROOT/picoshare" | awk '{print $5}')"
    log ""
}

# Update VM image with new binary
update_vm_image() {
    log "==================================================="
    log "Updating VM image with new binary..."
    log "==================================================="

    local rootfs="$SCRIPT_DIR/firecracker-images/rootfs-working.ext4"
    local mount_point="/mnt"

    if [[ ! -f "$rootfs" ]]; then
        log "ERROR: VM rootfs not found at $rootfs"
        exit 1
    fi

    log "Mounting $rootfs..."
    sudo mount -o loop "$rootfs" "$mount_point"

    log "Copying binary to /usr/local/bin/picoshare..."
    sudo cp "$PROJECT_ROOT/picoshare" "$mount_point/usr/local/bin/picoshare"

    log "Unmounting..."
    sudo umount "$mount_point"

    log "✓ VM image updated"
    log ""
}

# Build and update VM before running tests
log "==================================================="
log "Pre-test preparation"
log "==================================================="
log "Branch: $(git branch --show-current)"
log "Commit: $(git rev-parse --short HEAD)"
log ""

build_binary
update_vm_image

# Create results directory with branch name
TIMESTAMP=$(date +%Y%m%d-%H%M%S)
BRANCH_NAME=$(git branch --show-current | sed 's/perf\///')
RUN_DIR="$RESULTS_BASE_DIR/matrix-${BRANCH_NAME}-${TIMESTAMP}"
mkdir -p "$RUN_DIR"

SUMMARY_FILE="$RUN_DIR/summary.txt"
CSV_FILE="$RUN_DIR/matrix-results.csv"

# Initialize CSV
echo "ram_mb,file_size,boot_time_seconds,duration_seconds,throughput_mbps,http_status,exit_reason,success" > "$CSV_FILE"

log "==================================================="
log "PicoShare Firecracker Performance Test Matrix"
log "==================================================="
log "Memory configs: ${MEMORY_LIMITS[*]}"
log "File sizes: ${FILE_SIZES[*]}"
log "Total tests: $((${#MEMORY_LIMITS[@]} * ${#FILE_SIZES[@]}))"
log "Results directory: $RUN_DIR"
log ""

# Statistics
total_tests=$((${#MEMORY_LIMITS[@]} * ${#FILE_SIZES[@]}))
current_test=0
passed_tests=0
failed_tests=0
start_time=$(date +%s)

# Clean up any stale routes before starting
log "Cleaning up stale network routes..."
sudo ip route del 172.16.0.0/24 2>/dev/null || true

# Run tests
for memory in "${MEMORY_LIMITS[@]}"; do
    log "=========================================="
    log "Testing with ${memory}MB RAM"
    log "=========================================="
    log ""

    for size in "${FILE_SIZES[@]}"; do
        ((current_test++))
        log "[$current_test/$total_tests] Running: ${memory}MB RAM, ${size} file"

        # Clean up route before each test
        sudo ip route del 172.16.0.0/24 2>/dev/null || true

        # Run single test
        test_start=$(date +%s)

        # Run test and capture output
        if sudo "$SCRIPT_DIR/run-test" "$memory" "$size" 2>&1 | tee "$RUN_DIR/test-${memory}MB-${size}.log"; then
            result_file=$(grep '^/.*\.json$' "$RUN_DIR/test-${memory}MB-${size}.log" | tail -1)
            ((passed_tests++))
            test_status="PASS"
        else
            result_file=$(grep '^/.*\.json$' "$RUN_DIR/test-${memory}MB-${size}.log" | tail -1)
            ((failed_tests++))
            test_status="FAIL"
        fi

        test_end=$(date +%s)
        test_duration=$((test_end - test_start))

        # Extract result data and append to CSV
        if [[ -f "$result_file" ]] && command -v jq >/dev/null 2>&1; then
            jq -r '[.ram_mb, .file_size, .boot_time_seconds, .duration_seconds, .throughput_mbps, .http_status, .exit_reason, .success] | @csv' "$result_file" >> "$CSV_FILE"
        fi

        log "[$current_test/$total_tests] $test_status (took ${test_duration}s)"
        log ""

        # Brief pause between tests
        sleep 2
    done
done

end_time=$(date +%s)
total_duration=$((end_time - start_time))

# Generate summary
{
    echo "==================================================="
    echo "PicoShare Firecracker Performance Test Matrix Summary"
    echo "==================================================="
    echo ""
    echo "Timestamp: $(date -Iseconds)"
    echo "Total Duration: ${total_duration}s ($((total_duration / 60))m)"
    echo ""
    echo "Tests Run: $current_test / $total_tests"
    echo "Passed: $passed_tests"
    echo "Failed: $failed_tests"
    echo ""

    if [[ -f "$CSV_FILE" ]] && command -v column >/dev/null 2>&1; then
        echo "Results:"
        echo ""
        column -t -s',' "$CSV_FILE"
    fi
} | tee "$SUMMARY_FILE"

log ""
log "==================================================="
log "Test matrix complete!"
log "  Passed: $passed_tests"
log "  Failed: $failed_tests"
log "  Total:  $current_test"
log ""
log "Results saved to: $RUN_DIR"
log "==================================================="

exit $( [[ $failed_tests -eq 0 ]] && echo 0 || echo 1 )
